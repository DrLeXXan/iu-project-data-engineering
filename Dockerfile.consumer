# Use Apache Spark official image with Python support
FROM apache/spark-py:latest

USER 0

# Set working directory inside the container
WORKDIR /app

# Install system dependencies
# RUN apt-get update && apt-get install -y wget python3 python3-pip

# Upgrade pip and install required Python dependencies
# RUN python3 -m pip install --upgrade pip
RUN pip install pyspark kafka-python

# Ensure the Spark JARs directory exists
RUN mkdir -p /opt/spark/jars/

# Download required Spark-Kafka and PostgreSQL JARs
RUN wget -q https://repo1.maven.org/maven2/org/apache/spark/spark-sql-kafka-0-10_2.12/3.5.0/spark-sql-kafka-0-10_2.12-3.5.0.jar -P /opt/spark/jars/
RUN wget -q https://repo1.maven.org/maven2/org/postgresql/postgresql/42.6.0/postgresql-42.6.0.jar -P /opt/spark/jars/

# Copy the application script
COPY main.py .

# Set the command to execute the script
CMD ["python3", "main.py"]
